<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>Project AI</title>
        <style>
            * {
                box-sizing: border-box;
            }
            html {
                font-size: 62.5%;
            }

            body {
                font-size: 1.6rem;
                text-align: center;
                font-family: "Lato", sans-serif;
            }

            button {
                font-family: inherit;
            }

            .heading {
                background: linear-gradient(to right, #dcac58 0%, #25016e 100%);
                -webkit-background-clip: text;
                background-clip: text;
                color: transparent;
                pointer-events: none;
            }

            .btn-wrap {
                display: flex;
            }

            .btn {
                position: absolute;
                --height: 60px;
                display: inline-flex;
                align-items: flex-start;
                justify-content: flex-start;
                min-width: 150px;
                height: var(--height);
                line-height: var(--height);
                border-radius: 99px;
                background: transparent;
                border: transparent;
                font-size: 2rem;
                font-weight: 400;
                margin-bottom: 50px;
                transition: all 0.3s ease;
            }

            .info {
                position: fixed;
                border: 2px dotted #333;
                padding: 20px;
                margin: 0 20px 20px;
                bottom: 0;
                right: 0;
                pointer-events: none;
            }

            .info__name {
                font-size: 2rem;
            }
            #label-container {
                display: none;
                font-size: 2rem;
                color: red;
                font-weight: 600;
            }

            canvas {
                position: relative;
                z-index: 1;
                /* border: 3px dashed #d20707; */
            }
        </style>
    </head>
    <body>
        <!-- <h1 class="heading">Project AI - NHẬN DẠNG VẬT THỂ</h1> -->
        <!-- <div class="info">
            <p class="info__name">Đoàn Hoàng Bão</p>
            <p class="info__name">Trần Phú Hòa An</p>
        </div> -->
        <div class="btn-wrap">
            <button class="btn" type="button" onclick="init()"></button>
        </div>
        <div id="label-container"></div>
        <div id="webcam-container"></div>
        <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
        <script src="https://code.responsivevoice.org/responsivevoice.js?key=SzNvR57C"></script>
        <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
        <script type="text/javascript">
            // More API functions here:
            // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

            // the link to your model provided by Teachable Machine export panel
            const URL =
                "https://teachablemachine.withgoogle.com/models/ZQ_hmrrz9/";

            let model, webcam, labelContainer, maxPredictions;
            let lastLabel = "";
            // Load the image model and setup the webcam
            async function init() {
                const modelURL = URL + "model.json";
                const metadataURL = URL + "metadata.json";

                // load the model and metadata
                // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
                // or files from your local hard drive
                // Note: the pose library adds "tmImage" object to your window (window.tmImage)
                model = await tmImage.load(modelURL, metadataURL);
                maxPredictions = model.getTotalClasses();

                // Convenience function to setup a webcam
                const w = screen.availWidth;
                const h = screen.availHeight;
                const flip = true; // whether to flip the webcam
                webcam = new tmImage.Webcam(w, h, flip); // width, height, flip
                await webcam.setup(); // request access to the webcam
                await webcam.play();
                window.requestAnimationFrame(loop);

                // append elements to the DOM
                document
                    .getElementById("webcam-container")
                    .appendChild(webcam.canvas);
                labelContainer = document.getElementById("label-container");
            }

            async function loop() {
                webcam.update(); // update the webcam frame
                await predict();
                window.requestAnimationFrame(loop);
            }

            // run the webcam image through the image model
            async function predict() {
                // predict can take in an image, video or canvas html element
                const predictions = await model.predictTopK(webcam.canvas, 1);
                const label = predictions[0].className;
                if (label !== lastLabel) {
                    lastLabel = label;
                    responsiveVoice.speak(label, "Vietnamese Female");
                    labelContainer.innerText = predictions[0].className;
                }
            }
        </script>
    </body>
</html>
